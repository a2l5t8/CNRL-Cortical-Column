{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from conex import *\n",
    "from pymonntorch import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from conex.helpers.filters import DoGFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path,size = None):\n",
    "    img = cv2.imread(path)\n",
    "    if(size):\n",
    "        img = cv2.resize(img,size)\n",
    "    return torch.tensor(img[:,:,0],dtype=torch.float32)\n",
    "\n",
    "def show_image(image,normal=False):\n",
    "    plt.axis(\"off\")\n",
    "    if(normal):\n",
    "        plt.imshow(image,cmap='gray',vmin=0,vmax=255)\n",
    "    else:\n",
    "        plt.imshow(image,cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def show_filters(weight):\n",
    "    fig,axes = plt.subplots(1,weight.shape[0])\n",
    "    fig.set_size_inches(5*weight.shape[0], 5)\n",
    "    # fig.suptitle(f'plots of synaptic share weights for d = {weight.shape[0]}')\n",
    "    for i in range(weight.shape[0]):\n",
    "        axes[i].imshow(weight[i][0],cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        \n",
    "def show_images(imgs,title,count):\n",
    "    fig,axes = plt.subplots(1,count)\n",
    "    fig.set_size_inches(5*count, 5)\n",
    "    plt.text(x=0.5, y=0.94, s=title, fontsize=28, ha=\"center\", transform=fig.transFigure)\n",
    "    for i in range(count):\n",
    "        axes[i].imshow(imgs[i][0][0],cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prioritize behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{180: AveragePool2D(current_coef=1,),\n",
       " 220: SimpleDendriteStructure(Proximal_max_delay=1,Distal_max_delay=1,Apical_max_delay=None,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=None,),\n",
       " 240: SimpleDendriteComputation(I_tau=None,apical_provocativeness=None,distal_provocativeness=None,),\n",
       " 260: LIF(R=1,tau=10,threshold=-13,v_reset=-70,v_rest=-65,init_v=None,init_s=None,),\n",
       " 280: InherentNoise(mode=rand,scale=1,offset=0,),\n",
       " 320: SpikeNdDataset(dataloader=sensory,ndim_sensory=2,ndim_location=2,have_location=False,have_sensory=True,have_label=True,silent_interval=0,instance_duration=1,loop=True,),\n",
       " 340: Fire(),\n",
       " 380: NeuronAxon(max_delay=1,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=0,have_trace=None,)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prioritize_behaviors([\n",
    "    \n",
    "    LateralDendriticInput(current_coef=60, inhibitory=True),\n",
    "    Conv2dDendriticInput(current_coef = 1, stride = 1, padding = 0),\n",
    "    AveragePool2D(current_coef = 1),\n",
    "    SimpleDendriteStructure(),\n",
    "    SimpleDendriteComputation(),\n",
    "    LIF(\n",
    "        tau = 10,\n",
    "        R = 1,\n",
    "        threshold = -13,\n",
    "        v_rest = -65,\n",
    "        v_reset = -70\n",
    "    ),\n",
    "    InherentNoise(scale = 1, offset = 0),\n",
    "    SpikeNdDataset(\n",
    "        dataloader = \"sensory\",\n",
    "        instance_duration = 1\n",
    "    ),\n",
    "    Fire(),\n",
    "    NeuronAxon(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './first_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m time_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m      3\u001b[0m transformation \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mGrayscale(num_output_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;66;03m# not necessary\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     SimplePoisson(time_window \u001b[38;5;241m=\u001b[39m time_window , ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      9\u001b[0m ])\n\u001b[1;32m---> 10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./first_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m dl \u001b[38;5;241m=\u001b[39m DataLoader(dataset,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m show_image(torch\u001b[38;5;241m.\u001b[39msum(dataset[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './first_step'"
     ]
    }
   ],
   "source": [
    "time_window = 500\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels = 1), # not necessary\n",
    "    Conv2dFilter( DoGFilter(size = 5, sigma_1 = 4, sigma_2 = 1,zero_mean=True,one_sum=True).unsqueeze(0).unsqueeze(0)),\n",
    "    SqueezeTransform(dim = 0),\n",
    "    SimplePoisson(time_window = time_window , ratio = 2),\n",
    "])\n",
    "dataset = torchvision.datasets.ImageFolder(root=\"./first_step\",transform=transformation)\n",
    "dl = DataLoader(dataset,shuffle=True)\n",
    "show_image(torch.sum(dataset[1][0],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoG_SIZE = 5\n",
    "IMAGE_WIDTH = 14\n",
    "IMAGE_HEIGHT = 14\n",
    "\n",
    "OUT_CHANNEL = 5\n",
    "IN_CHANNEL = 1\n",
    "KERNEL_WIDTH = 10\n",
    "KERNEL_HEIGHT = 10\n",
    "\n",
    "INPUT_WIDTH = IMAGE_WIDTH - DoG_SIZE + 1\n",
    "INPUT_HEIGHT = IMAGE_HEIGHT - DoG_SIZE + 1\n",
    "\n",
    "L4_WIDTH = INPUT_WIDTH - KERNEL_WIDTH + 1\n",
    "L4_HEIGHT = INPUT_HEIGHT - KERNEL_HEIGHT + 1\n",
    "\n",
    "L23_WIDTH = L4_WIDTH//2\n",
    "L23_HEIGHT = L4_HEIGHT//2\n",
    "\n",
    "J_0 = 300\n",
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neocortex(dt=1, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "#################### Input Layer ####################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_layer = InputLayer(\n",
    "    net=net,\n",
    "    input_dataloader= dl,\n",
    "    sensory_data_dim=2,\n",
    "    sensory_size = NeuronDimension(depth=1, height = INPUT_HEIGHT, width = INPUT_WIDTH),\n",
    "    sensory_trace= 3,\n",
    "    instance_duration= time_window,\n",
    "    silent_interval=100,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################### L4 ####################\n",
    "\n",
    "\n",
    "\n",
    "ng4e = NeuronGroup(size = NeuronDimension(depth = OUT_CHANNEL , height = L4_HEIGHT, width = L4_WIDTH), net = net, behavior = prioritize_behaviors([\n",
    "    SimpleDendriteStructure(),\n",
    "    SimpleDendriteComputation(),\n",
    "    LIF(\n",
    "        init_v = -65,\n",
    "        tau = 7,\n",
    "        R = 10,\n",
    "        threshold = -13,\n",
    "        v_rest = -65,\n",
    "        v_reset = -70,\n",
    "    ),\n",
    "    KWTA(k=5),\n",
    "    ActivityBaseHomeostasis(window_size=10, activity_rate=200, updating_rate=0.0001),\n",
    "    Fire(),\n",
    "    SpikeTrace(tau_s = 15),\n",
    "    NeuronAxon(),\n",
    "]) | ({\n",
    "    800 : Recorder(variables = ['v', \"I\", \"torch.mean(I)\", \"trace\", \"n.spikes.sum()/n.size\"]),\n",
    "    801 : EventRecorder(['spikes'])\n",
    "}))\n",
    "\n",
    "ng4i = NeuronGroup(size = L4_HEIGHT * L4_WIDTH * OUT_CHANNEL // 4, net = net, tag = \"inh\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriteStructure(),\n",
    "    SimpleDendriteComputation(),\n",
    "    LIF(\n",
    "        init_v = -65,\n",
    "        tau = 7,\n",
    "        R = 10,\n",
    "        threshold = -13,\n",
    "        v_rest = -65,\n",
    "        v_reset = -70\n",
    "    ),\n",
    "    # KWTA(k=30),\n",
    "    Fire(),\n",
    "    SpikeTrace(tau_s = 5, offset = 0),\n",
    "    NeuronAxon(),\n",
    "]) | ({\n",
    "    800 : Recorder(variables = ['v', \"I\", \"torch.mean(I)\", \"trace\", \"n.spikes.sum()/n.size\"]),\n",
    "    801 : EventRecorder(['spikes'])\n",
    "}))\n",
    "\n",
    "\n",
    "sgi4e = SynapseGroup(net = net, src = input_layer.sensory_pop, dst = ng4e, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(weights = torch.normal(0.5, 2, (OUT_CHANNEL, IN_CHANNEL, KERNEL_HEIGHT, KERNEL_WIDTH)) ),\n",
    "    Conv2dDendriticInput(current_coef = 35 , stride = 1, padding = 0),\n",
    "    Conv2dSTDP(a_plus=0.05, a_minus=0.004),\n",
    "    WeightNormalization(norm = 50)\n",
    "]))\n",
    "\n",
    "\n",
    "sg4e4i = SynapseGroup(net = net, src = ng4e, dst = ng4i, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriticInput(),\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(mode = \"ones\", scale = J_0/math.sqrt(400 * p), density = 0.02, true_sparsity = False),\n",
    "]))\n",
    "\n",
    "\n",
    "sg4i4e = SynapseGroup(net = net, src = ng4i, dst = ng4e, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriticInput(),\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(mode = \"ones\", scale = J_0/math.sqrt(400 * p), density = 0.02, true_sparsity = False),\n",
    "]))\n",
    "\n",
    "sg4e4e = SynapseGroup(net = net, src = ng4e, dst = ng4e, tag = \"Proximal\", behavior=prioritize_behaviors([\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(weights=torch.Tensor([1, 1, 1, 1, 0, 1, 1, 1, 1]).view(1, 1, 9, 1, 1)),\n",
    "    LateralDendriticInput(current_coef=1300, inhibitory = True),\n",
    "])| {\n",
    "    600 : Recorder([\"I\"])\n",
    "})\n",
    "\n",
    "sg4i4i = SynapseGroup(net = net, src = ng4i, dst = ng4i, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriticInput(),\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(mode = \"ones\", scale = J_0/math.sqrt(400 * p), density = 0.02, true_sparsity = False),\n",
    "]))\n",
    "\n",
    "\n",
    "\n",
    "#################### L2&3 ####################\n",
    "\n",
    "\n",
    "\n",
    "ng23e = NeuronGroup(size = NeuronDimension(depth = OUT_CHANNEL , height = L23_HEIGHT, width = L23_WIDTH), net = net, behavior = prioritize_behaviors([\n",
    "    SimpleDendriteStructure(),\n",
    "    SimpleDendriteComputation(),\n",
    "    LIF(\n",
    "        init_v = -65,\n",
    "        tau = 7,\n",
    "        R = 10,\n",
    "        threshold = -13,\n",
    "        v_rest = -65,\n",
    "        v_reset = -70\n",
    "    ),\n",
    "    Fire(),\n",
    "    SpikeTrace(tau_s = 15),\n",
    "    NeuronAxon(),\n",
    "]) | ({\n",
    "    800 : Recorder(['v', \"I\", \"torch.mean(I)\", \"trace\", \"n.spikes.sum()/n.size\"]),\n",
    "    801 : EventRecorder(['spikes'])\n",
    "}))\n",
    "\n",
    "ng23i = NeuronGroup(size = L23_HEIGHT * L23_WIDTH * OUT_CHANNEL // 4, net = net, tag = \"inh\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriteStructure(),\n",
    "    SimpleDendriteComputation(),\n",
    "    LIF(\n",
    "        init_v = -65,\n",
    "        tau = 7,\n",
    "        R = 10,\n",
    "        threshold = -13,\n",
    "        v_rest = -65,\n",
    "        v_reset = -70\n",
    "    ),\n",
    "    Fire(),\n",
    "    SpikeTrace(tau_s = 15),\n",
    "    NeuronAxon(),\n",
    "]) | ({\n",
    "    800 : Recorder(['v', \"I\", \"torch.mean(I)\", \"trace\", \"n.spikes.sum()/n.size\"]),\n",
    "    801 : EventRecorder(['spikes'])\n",
    "}))\n",
    "\n",
    "sg4e23e = SynapseGroup(net = net, src = ng4e, dst = ng23e, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SynapseInit(),\n",
    "    # WeightInitializer(mode = \"normal(4, 5)\", density = 0.02, true_sparsity = False),\n",
    "    AveragePool2D(current_coef = 150),\n",
    "]) | ({\n",
    "    800 : Recorder([\"I\"]),\n",
    "}))\n",
    "\n",
    "sg23e23i = SynapseGroup(net = net, src = ng23e, dst = ng23i, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriticInput(),\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(mode = \"ones\", scale = J_0/math.sqrt(625 * p), density = 0.02, true_sparsity = False),\n",
    "]) | ({\n",
    "    800 : Recorder([\"I\"]),\n",
    "}))\n",
    "\n",
    "sg23i23e = SynapseGroup(net = net, src = ng23i, dst = ng23e, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriticInput(),\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(mode = \"ones\", scale = J_0/math.sqrt(625 * p), density = 0.02, true_sparsity = False),\n",
    "]) | ({\n",
    "    800 : Recorder([\"I\"]),\n",
    "}))\n",
    "\n",
    "sg23i23i = SynapseGroup(net = net, src = ng23i, dst = ng23i, tag = \"Proximal\", behavior = prioritize_behaviors([\n",
    "    SimpleDendriticInput(),\n",
    "    SynapseInit(),\n",
    "    WeightInitializer(mode = \"ones\", scale = J_0/math.sqrt(625 * p), density = 0.02, true_sparsity = False),\n",
    "]) | ({\n",
    "    800 : Recorder([\"I\"]),\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network['Neocortex'](Neurons: tensor(106)|5 groups, Synapses: tensor(536)|9 groups){1:TimeResolution(dt=1,)}\n",
      "NeuronGroup['Sensory', 'NeuronGroup', 'ng'](100){0:NeuronDimension(depth=1,height=10,width=10,input_patterns=None,)340:SensorySetter()360:SpikeTrace(tau_s=3,)380:NeuronAxon(max_delay=1,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=0,have_trace=None,)}\n",
      "NeuronGroup['NeuronGroup_2', 'NeuronGroup', 'ng'](5){0:NeuronDimension(depth=5,height=1,width=1,input_patterns=None,)220:SimpleDendriteStructure(Proximal_max_delay=1,Distal_max_delay=1,Apical_max_delay=None,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=None,)240:SimpleDendriteComputation(I_tau=None,apical_provocativeness=None,distal_provocativeness=None,)260:LIF(R=10,tau=7,threshold=-13,v_reset=-70,v_rest=-65,init_v=-65,init_s=None,)300:KWTA(k=5,dimension=None,)340:Fire()341:ActivityBaseHomeostasis(activity_rate=200,window_size=10,updating_rate=0.0001,decay_rate=1.0,)360:SpikeTrace(tau_s=15,)380:NeuronAxon(max_delay=1,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=0,have_trace=None,)800:Recorder(variables=['v', 'I', 'torch.mean(I)', 'trace', 'n.spikes.sum()/n.size'],gap_width=0,max_length=None,auto_annotate=True,tag=None,)801:EventRecorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['spikes'],)}\n",
      "NeuronGroup['inh', 'NeuronGroup', 'ng'](1){220:SimpleDendriteStructure(Proximal_max_delay=1,Distal_max_delay=1,Apical_max_delay=None,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=None,)240:SimpleDendriteComputation(I_tau=None,apical_provocativeness=None,distal_provocativeness=None,)260:LIF(R=10,tau=7,threshold=-13,v_reset=-70,v_rest=-65,init_v=-65,init_s=None,)340:Fire()360:SpikeTrace(tau_s=5,offset=0,)380:NeuronAxon(max_delay=1,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=0,have_trace=None,)800:Recorder(variables=['v', 'I', 'torch.mean(I)', 'trace', 'n.spikes.sum()/n.size'],gap_width=0,max_length=None,auto_annotate=True,tag=None,)801:EventRecorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['spikes'],)}\n",
      "NeuronGroup['NeuronGroup_4', 'NeuronGroup', 'ng'](0){0:NeuronDimension(depth=5,height=0,width=0,input_patterns=None,)220:SimpleDendriteStructure(Proximal_max_delay=1,Distal_max_delay=1,Apical_max_delay=None,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=None,)240:SimpleDendriteComputation(I_tau=None,apical_provocativeness=None,distal_provocativeness=None,)260:LIF(R=10,tau=7,threshold=-13,v_reset=-70,v_rest=-65,init_v=-65,init_s=None,)340:Fire()360:SpikeTrace(tau_s=15,)380:NeuronAxon(max_delay=1,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=0,have_trace=None,)800:Recorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['v', 'I', 'torch.mean(I)', 'trace', 'n.spikes.sum()/n.size'],)801:EventRecorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['spikes'],)}\n",
      "NeuronGroup['inh', 'NeuronGroup', 'ng'](0){220:SimpleDendriteStructure(Proximal_max_delay=1,Distal_max_delay=1,Apical_max_delay=None,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=None,)240:SimpleDendriteComputation(I_tau=None,apical_provocativeness=None,distal_provocativeness=None,)260:LIF(R=10,tau=7,threshold=-13,v_reset=-70,v_rest=-65,init_v=-65,init_s=None,)340:Fire()360:SpikeTrace(tau_s=15,)380:NeuronAxon(max_delay=1,proximal_min_delay=0,distal_min_delay=0,apical_min_delay=0,have_trace=None,)800:Recorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['v', 'I', 'torch.mean(I)', 'trace', 'n.spikes.sum()/n.size'],)801:EventRecorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['spikes'],)}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'Sensory => NeuronGroup_2'](S100xD5){2:SynapseInit(),3:WeightInitializer(mode=None,scale=1,offset=0,function=None,density=1,true_sparsity=True,weight_shape=None,kernel_shape=None,weights=tensor([[[[-4.2225e-01,  1.0916e+00,  3.2816e+00, -7.0349e-01,  1.1309e+00,\n",
      "            6.6435e-01,  3.1066e+00, -2.4330e-02, -1.2104e-01, -3.1037e+00],\n",
      "          [-2.7659e+00,  2.0308e+00, -1.7094e-02,  1.0180e-01,  1.8879e+00,\n",
      "            1.2083e+00, -2.2631e+00,  2.3498e+00,  2.2476e+00,  1.7420e+00],\n",
      "          [ 3.4911e-01,  1.7198e+00, -4.7378e-01,  6.3344e+00, -8.3865e-01,\n",
      "            1.9222e-01,  1.6987e+00, -4.8897e-01,  2.9685e+00,  1.5905e+00],\n",
      "          [-3.2468e+00,  3.4890e+00, -3.5527e+00, -2.2227e+00, -3.0358e+00,\n",
      "           -7.2877e-01,  2.1900e+00,  5.3429e-01,  9.0209e-02,  2.7729e+00],\n",
      "          [-9.9844e-01,  1.7090e+00,  9.8754e-01,  1.9353e+00, -6.5233e-01,\n",
      "           -7.3269e-01,  7.0626e-01,  1.6450e+00,  3.8157e-01,  2.8231e+00],\n",
      "          [ 6.8834e-01,  3.0404e+00,  2.9924e+00, -1.6161e+00, -1.1583e+00,\n",
      "            3.1723e+00, -2.4829e-01,  1.5463e+00, -4.0716e-01, -1.0493e+00],\n",
      "          [-9.8884e-01, -2.1690e+00, -3.9843e-01, -1.2005e+00, -1.6545e-01,\n",
      "            2.0514e+00,  1.6257e+00,  1.4090e+00,  6.9491e-01, -1.2331e-01],\n",
      "          [ 4.6136e-01,  5.4070e-01, -2.7120e+00, -5.4929e-01,  1.6936e+00,\n",
      "            9.6967e-02,  1.9537e+00,  7.4688e-01, -1.2439e-01, -9.8083e-01],\n",
      "          [-3.7127e+00, -3.0155e-01,  3.3613e+00,  3.5422e+00,  3.9879e-02,\n",
      "            1.8534e+00,  6.5817e+00, -1.1476e-01, -5.0803e+00, -8.3689e-01],\n",
      "          [ 9.8338e-01,  2.5086e+00,  1.9552e+00,  2.2072e+00, -3.6883e+00,\n",
      "            2.1439e+00, -2.6426e+00, -3.1153e-01,  1.4626e+00,  2.7205e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5602e+00, -4.3449e-01, -3.4162e+00, -2.2085e+00, -2.2022e-01,\n",
      "           -1.0247e+00,  3.7132e-01, -9.6231e-01,  2.3138e-01,  1.2273e+00],\n",
      "          [ 1.0416e+00, -2.7643e+00, -5.4163e-01, -2.5047e+00,  3.1157e+00,\n",
      "           -4.8878e-01,  2.9832e+00, -1.9443e+00, -7.1077e-01,  1.0083e+00],\n",
      "          [-4.9190e+00,  1.1968e+00,  1.2760e+00, -2.8352e-01, -3.5191e+00,\n",
      "            1.8077e+00,  1.4169e+00, -3.4903e+00, -2.7846e-01, -7.0606e-01],\n",
      "          [-2.0260e+00, -1.2161e+00,  3.7038e+00, -3.5691e-02,  2.2000e+00,\n",
      "            6.2618e-01,  2.8592e-01, -5.7721e-01, -2.2537e-01,  1.9957e+00],\n",
      "          [ 2.5874e+00, -3.5432e+00, -1.0771e-01, -1.5785e+00,  3.0202e-01,\n",
      "           -6.1430e-01,  1.8732e+00,  2.3439e+00, -2.5154e+00, -1.1105e+00],\n",
      "          [ 3.0195e+00,  3.2749e+00,  2.3515e+00,  9.5262e-01, -4.5330e-01,\n",
      "            1.9558e+00, -1.2641e+00,  2.8596e+00, -1.1902e+00,  1.4404e+00],\n",
      "          [ 2.9422e+00,  3.4486e+00,  4.4192e+00, -2.2261e+00, -2.5176e+00,\n",
      "            2.2936e+00, -2.1580e+00,  2.6628e-01, -1.8653e-01,  2.2104e+00],\n",
      "          [-5.0081e+00,  1.4557e+00,  3.8816e-01,  1.0204e+00,  1.7140e+00,\n",
      "           -5.6871e-01, -1.1940e+00, -1.0735e+00,  2.2296e+00,  1.3361e+00],\n",
      "          [-3.4990e-01, -5.3016e-01, -2.1616e+00, -5.5490e-01,  1.8246e+00,\n",
      "           -2.0495e-01,  3.1601e+00, -2.2144e+00,  2.4098e+00, -4.7848e-01],\n",
      "          [ 4.3253e+00, -9.9651e-01, -1.2058e+00,  4.8518e+00,  1.9441e+00,\n",
      "            3.6227e+00, -7.4712e-01,  2.1874e+00, -1.9643e+00,  3.3161e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.9308e-02, -1.9161e+00, -2.8077e+00,  7.3811e-01,  1.1900e+00,\n",
      "            6.2024e-01,  1.8674e+00, -9.3936e-01,  6.2217e-02,  1.5466e+00],\n",
      "          [ 3.5399e+00,  1.2492e+00,  3.1217e+00,  9.9310e-01,  3.5407e+00,\n",
      "            1.6809e+00,  7.3286e-01,  5.7213e-02,  1.8383e+00,  8.4357e-01],\n",
      "          [ 4.2926e+00, -2.9515e+00, -2.1260e+00,  4.5108e+00,  8.2088e-01,\n",
      "            3.2848e+00, -1.2572e+00,  2.0126e+00,  1.4253e-02, -4.7911e-01],\n",
      "          [-2.1501e+00, -1.6694e+00,  4.8728e+00,  2.2385e+00,  2.0151e+00,\n",
      "           -1.5225e+00,  8.1930e-01,  1.1079e+00,  1.2499e+00,  8.2507e-01],\n",
      "          [-2.8398e-01, -4.0305e+00, -1.0253e+00,  8.2982e-01,  9.7862e-01,\n",
      "            2.6893e+00, -1.8071e+00,  1.2481e+00,  5.3063e-01,  4.2012e+00],\n",
      "          [-2.3049e-01, -1.9513e+00,  1.4738e+00,  1.1059e+00,  3.2168e+00,\n",
      "            4.4346e+00, -3.6919e-02,  3.6229e+00,  3.3935e+00,  2.2110e-01],\n",
      "          [ 7.7753e-01,  8.9825e-02, -5.1929e-01,  1.0027e+00, -1.1590e+00,\n",
      "           -1.7306e+00,  1.9864e+00,  6.6588e-01,  1.7104e+00,  1.9116e-01],\n",
      "          [ 4.0550e-02,  1.6017e+00,  2.9092e+00, -2.5252e+00,  9.1050e-02,\n",
      "           -4.4487e-01, -5.4417e+00,  5.0435e+00,  5.2868e+00,  1.2934e+00],\n",
      "          [ 1.9336e+00,  1.0930e-01, -3.1952e-01, -4.4013e-01,  2.3695e+00,\n",
      "            1.7887e+00, -3.4556e+00,  1.4338e+00,  1.7168e+00, -1.3372e+00],\n",
      "          [ 2.1009e+00, -5.5094e-01,  2.0513e+00,  6.8110e-01,  1.1764e-01,\n",
      "            8.0590e-01,  8.0431e-02, -5.6318e-01, -2.9855e-02,  5.4332e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9197e-01, -2.9163e+00,  5.8607e-01,  3.8502e+00,  9.6556e-01,\n",
      "           -2.8265e-01, -1.5490e-01,  5.4264e-01, -1.4331e+00, -8.6091e-01],\n",
      "          [ 3.6102e+00, -1.2231e+00, -1.2381e-01,  3.6588e+00, -6.6374e-01,\n",
      "           -1.3907e+00,  2.0283e-01,  3.8549e+00,  1.0394e+00, -1.6458e+00],\n",
      "          [ 2.4052e-02, -2.4235e+00,  3.4989e-02,  3.6735e+00, -2.1665e+00,\n",
      "            1.6884e+00,  1.8143e+00,  7.1305e-01, -1.2665e+00,  2.6468e+00],\n",
      "          [ 3.5303e+00, -8.6445e-01,  2.4685e+00, -1.2218e+00, -1.4742e+00,\n",
      "            2.7293e-01, -1.6060e+00,  1.6756e+00,  3.0157e-01,  7.3338e-01],\n",
      "          [ 7.6898e-01,  3.7237e+00, -3.1788e+00, -1.1581e+00, -4.2346e-02,\n",
      "            1.4008e+00,  8.6031e-01,  1.2488e+00,  9.6734e-01, -4.2100e-01],\n",
      "          [ 1.6508e+00,  1.9284e+00, -1.6377e-01,  4.3633e+00,  1.8949e+00,\n",
      "           -1.1218e+00,  2.4058e+00,  8.2316e-01, -7.8474e-01, -1.3864e+00],\n",
      "          [-7.5648e-01, -4.5030e+00,  3.2634e+00,  1.7254e+00,  2.6619e+00,\n",
      "            5.1456e-01,  3.6709e+00,  4.3134e-01, -2.9684e-01,  5.8975e-01],\n",
      "          [ 1.5580e+00,  2.9759e+00, -1.9106e-02, -1.1374e+00, -3.2173e-01,\n",
      "           -2.1094e+00,  2.2514e-01, -1.2104e+00,  5.2909e+00,  1.7651e+00],\n",
      "          [-3.7202e+00,  1.0726e+00,  1.2114e+00, -1.0570e-01, -1.7859e-01,\n",
      "           -6.2800e-01, -1.4571e+00,  2.2718e+00,  3.8144e+00,  1.9108e+00],\n",
      "          [ 1.7528e+00,  1.1663e+00,  1.5345e+00,  9.1535e-01,  6.4746e+00,\n",
      "           -2.1467e+00,  2.3097e+00,  1.6911e+00,  1.0472e+00, -1.2384e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8216e-01,  9.5859e-01, -2.0390e+00,  9.1547e-01,  2.0204e+00,\n",
      "           -3.3948e+00, -5.2465e-01,  4.0463e+00, -1.6705e+00,  3.2095e+00],\n",
      "          [ 5.2874e+00,  1.5264e+00, -1.0223e+00, -1.2722e+00,  4.2461e-01,\n",
      "            1.1999e+00,  5.9593e-01,  1.0079e+00, -2.0840e+00,  1.1306e+00],\n",
      "          [ 2.5990e+00, -1.0992e+00,  2.9805e+00, -1.7618e-01,  4.0223e+00,\n",
      "            7.2517e-01,  1.5626e+00, -1.3098e-03,  1.7744e+00,  4.4021e+00],\n",
      "          [ 2.4760e+00, -2.0048e+00, -2.2164e+00,  8.4438e-01, -1.0680e+00,\n",
      "           -7.6033e-01, -1.7735e-01, -9.4273e-01,  1.8232e-01,  1.0252e+00],\n",
      "          [-7.8261e-01,  8.0218e-01,  8.4772e-01,  5.4092e-01, -3.4964e-01,\n",
      "           -2.2348e+00,  3.1177e+00,  1.3434e+00,  3.8978e+00,  1.1090e+00],\n",
      "          [ 5.0870e-01,  6.8801e-02,  3.1436e+00,  3.4730e+00, -4.2327e+00,\n",
      "            6.5943e-01, -1.3121e+00, -3.3173e-01,  6.5980e-01,  1.0297e+00],\n",
      "          [-2.0717e+00,  1.0280e+00,  2.4452e+00, -3.6457e+00, -9.5178e-01,\n",
      "            7.6876e-01,  2.4758e+00,  1.2851e+00,  3.0921e+00,  5.5473e+00],\n",
      "          [ 4.7121e-01, -2.1903e+00, -9.7139e-01, -2.9920e+00,  9.1354e-01,\n",
      "            2.0254e+00,  5.7693e-02,  1.0329e+00, -5.4814e-01,  2.7609e+00],\n",
      "          [ 5.5835e+00,  2.0224e+00, -2.6107e-01, -6.3491e-01, -1.1978e+00,\n",
      "            5.1339e-02,  4.8868e+00, -6.9004e-01, -1.6108e-01, -1.1631e+00],\n",
      "          [ 2.7097e+00, -1.4061e+00,  3.0008e+00, -3.5781e+00,  3.4212e+00,\n",
      "           -1.4086e-01, -4.2453e-01, -4.1436e+00,  3.4536e-02,  2.0852e+00]]]]),),180:Conv2dDendriticInput(current_coef=35,stride=1,padding=0,),400:Conv2dSTDP(a_plus=0.05,a_minus=0.004,w_min=0.0,w_max=1.0,positive_bound=None,negative_bound=None,),420:WeightNormalization(norm=50,),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'NeuronGroup_2 => inh'](S5xD1){2:SynapseInit(),3:WeightInitializer(mode=ones,scale=16.77050983124842,offset=0,function=None,density=0.02,true_sparsity=False,weight_shape=None,kernel_shape=None,weights=None,),180:SimpleDendriticInput(current_coef=1,),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'inh => NeuronGroup_2'](S1xD5){2:SynapseInit(),3:WeightInitializer(mode=ones,scale=16.77050983124842,offset=0,function=None,density=0.02,true_sparsity=False,weight_shape=None,kernel_shape=None,weights=None,),180:SimpleDendriticInput(current_coef=1,),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'NeuronGroup_2 => NeuronGroup_2'](S5xD5){2:SynapseInit(),3:WeightInitializer(mode=None,scale=1,offset=0,function=None,density=1,true_sparsity=True,weight_shape=None,kernel_shape=None,weights=tensor([[[[[1.]],\n",
      "\n",
      "          [[1.]],\n",
      "\n",
      "          [[1.]],\n",
      "\n",
      "          [[1.]],\n",
      "\n",
      "          [[0.]],\n",
      "\n",
      "          [[1.]],\n",
      "\n",
      "          [[1.]],\n",
      "\n",
      "          [[1.]],\n",
      "\n",
      "          [[1.]]]]]),),180:LateralDendriticInput(current_coef=1300,inhibitory=True,),600:Recorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['I'],),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'inh => inh'](S1xD1){2:SynapseInit(),3:WeightInitializer(mode=ones,scale=16.77050983124842,offset=0,function=None,density=0.02,true_sparsity=False,weight_shape=None,kernel_shape=None,weights=None,),180:SimpleDendriticInput(current_coef=1,),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'NeuronGroup_2 => NeuronGroup_4'](S5xD0){2:SynapseInit(),180:AveragePool2D(current_coef=150,),800:Recorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['I'],),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'NeuronGroup_4 => inh'](S0xD0){2:SynapseInit(),3:WeightInitializer(mode=ones,scale=13.416407864998737,offset=0,function=None,density=0.02,true_sparsity=False,weight_shape=None,kernel_shape=None,weights=None,),180:SimpleDendriticInput(current_coef=1,),800:Recorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['I'],),}\n",
      "SynapseGroup['Proximal', 'SynapseGroup', 'syn', 'inh => NeuronGroup_4'](S0xD0){2:SynapseInit(),3:WeightInitializer(mode=ones,scale=13.416407864998737,offset=0,function=None,density=0.02,true_sparsity=False,weight_shape=None,kernel_shape=None,weights=None,),180:SimpleDendriticInput(current_coef=1,),800:Recorder(variables=None,gap_width=0,max_length=None,auto_annotate=True,tag=None,arg_0=['I'],),}\n",
      "InputLayer(Sensory Population Sensory(100)320:SpikeNdDataset(dataloader=<torch.utils.data.dataloader.DataLoader object at 0x0000024825E30FB0>,ndim_sensory=2,ndim_location=2,have_location=False,have_sensory=True,have_label=True,silent_interval=100,instance_duration=500,loop=True,)}\n",
      "Warning: \"offset\" not used in initialize of SpikeTrace(tau_s=5,offset=0,) behavior! Make sure that \"offset\" is spelled correctly and parameter(offset,...) is called in initialize. Valid attributes are: \"behavior_enabled\", \"tag\", \"device\", \"tau_s\".\n",
      "Warning: NeuronGroup Tag \"inh\" already in use. The first Tag of an Object should be unique and will be renamed to \"inhb\". Multiple Tags can be separated with a \",\" (NeuronGroup(..., tag=\"tag1,tag2,...\"))\n",
      "3000xBatch: 1/1 (100%) 24832.917ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24832.916975021362"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.simulate_iterations(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_filters(sgi4e.weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
